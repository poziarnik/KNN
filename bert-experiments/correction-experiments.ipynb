{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DATASET = Path(\"../data/masked.json\")\n",
    "\n",
    "MODEL = \"ufal/robeczech-base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "df = pd.read_json(DATASET)\n",
    "df.head()\n",
    "dataset = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "corrector = pipeline(\"fill-mask\", model=MODEL, tokenizer=MODEL, device=0, top_k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_sentences = dataset[\"masked\"]\n",
    "\n",
    "for predictions in corrector(masked_sentences[0]):\n",
    "    print(predictions[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHARDS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from typing import Callable, Iterator\n",
    "\n",
    "def explode_masked_and_fix(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.explode(\"masked\")\n",
    "    df[\"fix\"] = None\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    return df\n",
    "\n",
    "def _merge_masked(row):\n",
    "    sentence = row[\"error\"].split(' ')\n",
    "    for i, masked in enumerate(row[\"masked\"]):\n",
    "        try:\n",
    "            sentence[masked.split(\" \").index(\"[MASK]\")] = \"[MASK]\"\n",
    "        except ValueError:\n",
    "            del row[\"fix\"][i]\n",
    "\n",
    "    return row[\"sentence\"], \" \".join(sentence), row[\"fix\"]\n",
    "\n",
    "def implode_and_merge_masked(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.groupby([\"sentence\", \"error\"]).agg(\n",
    "        {\n",
    "            \"masked\": list,\n",
    "            \"fix\": list,\n",
    "        }\n",
    "    ).reset_index()\n",
    "\n",
    "    df[\"sentence\"], df[\"masked\"], df[\"fix\"] = zip(*df.apply(_merge_masked, axis=1))\n",
    "    return df\n",
    "\n",
    "def create_dataset(fnc: Callable[[Iterator[dict[str, str]]], Iterator[str]]) -> pd.DataFrame:\n",
    "    final_df = pd.DataFrame()\n",
    "\n",
    "    for i in tqdm(range(SHARDS)):\n",
    "        _dataset = dataset.shard(num_shards=SHARDS, index=i)\n",
    "\n",
    "        df = _dataset.to_pandas()\n",
    "        df = explode_masked_and_fix(df)\n",
    "\n",
    "        predictions = corrector(df[\"masked\"].to_list(), batch_size=32)\n",
    "\n",
    "        temp = [{\"error\": df.iloc[j][\"error\"],\n",
    "                 \"masked\": df.iloc[j][\"masked\"],\n",
    "                 \"predictions\": prediction } for j, prediction in enumerate(predictions)]\n",
    "\n",
    "\n",
    "        for j, prediction in enumerate(fnc(temp)):\n",
    "            df.loc[j, \"fix\"] = prediction\n",
    "\n",
    "        df = implode_and_merge_masked(df)\n",
    "\n",
    "        final_df = pd.concat([final_df, df], ignore_index=True)\n",
    "\n",
    "    return final_df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1\n",
    "We will replace `[MASK]` with the suggestion that has biggest score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_prediction(data: Iterator[dict[str, str]]) -> Iterator[str]:\n",
    "    for row in data:\n",
    "        yield row[\"predictions\"][0][\"token_str\"].strip()\n",
    "\n",
    "result = create_dataset(process_prediction)\n",
    "result.to_json(DATASET.parent / \"result-experiment-1.json\", orient=\"records\", lines=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
