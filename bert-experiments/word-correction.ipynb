{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DATASET = Path(\"../data/err-0.8/masked.json\")\n",
    "\n",
    "MODEL = \"ufal/robeczech-base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "dataset = Dataset.from_json(str(DATASET))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "corrector = pipeline(\"fill-mask\", model=MODEL, tokenizer=MODEL, device=0, top_k=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.9997588992118835, 'token': 2, 'token_str': '[SEP]', 'sequence': ''}\n"
     ]
    }
   ],
   "source": [
    "masked_sentences = dataset[\"masked\"]\n",
    "\n",
    "for predictions in corrector(masked_sentences[0]):\n",
    "    print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "SHARDS = math.ceil(len(dataset) / 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from typing import Iterator\n",
    "from transformers import Pipeline\n",
    "from dataclasses import dataclass\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class PredictionData:\n",
    "    sentence: str\n",
    "    error: str\n",
    "    masked: list[str]\n",
    "    predictions: list[dict[str, str]]\n",
    "\n",
    "\n",
    "class ProcessPrediction:\n",
    "    def __init__(self, pipeline: Pipeline):\n",
    "        self.pipeline = pipeline\n",
    "\n",
    "    def process_prediction(self, data: list[PredictionData]) -> Iterator[str]:\n",
    "        raise NotImplementedError(\"Implement this method\")\n",
    "\n",
    "def join_masked(row: list[str]) -> str | None:\n",
    "    is_all_floats = all(isinstance(item, float) for item in row)\n",
    "    if is_all_floats:\n",
    "        return None\n",
    "\n",
    "    masks: list[list[str]] = [\n",
    "        masked.split() for masked in row\n",
    "    ]\n",
    "\n",
    "    sentence: list[str] = []\n",
    "\n",
    "    for elements in zip(*masks):\n",
    "        if \"[MASK]\" in elements:\n",
    "            sentence.append(\"[MASK]\")\n",
    "        else:\n",
    "            sentence.append(elements[0])\n",
    "    \n",
    "    return \" \".join(sentence)\n",
    "\n",
    "def create_dataset(pred: ProcessPrediction) -> Dataset:\n",
    "    final_dataset = pd.DataFrame()\n",
    "\n",
    "    for i in tqdm(range(SHARDS), desc=\"Filling masks for shards\"):\n",
    "        _dataset = dataset.shard(num_shards=SHARDS, index=i)\n",
    "\n",
    "        # explode dataset so we can use it in the pipeline\n",
    "        df = _dataset.to_pandas()\n",
    "\n",
    "        df = df.explode(\"masked\")\n",
    "        df[\"replace\"] = None\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        not_nan = df[df[\"masked\"].notnull()].index\n",
    "\n",
    "        df_to_process = df.loc[not_nan]\n",
    "\n",
    "        # apply pipeline\n",
    "        predictions = corrector(df_to_process[\"masked\"].to_list(), batch_size=32)\n",
    "\n",
    "        # process predictions\n",
    "        prediction_data: list[PredictionData] = [\n",
    "            PredictionData(\n",
    "                sentence=row.sentence,\n",
    "                error=row.error,\n",
    "                masked=row.masked,\n",
    "                predictions=pred\n",
    "            ) for row, pred in zip(df_to_process.itertuples(), predictions)\n",
    "        ]\n",
    "\n",
    "        for j, prediction in enumerate(pred.process_prediction(prediction_data)):\n",
    "            df_to_process.loc[j, \"replace\"] = prediction\n",
    "\n",
    "        df.loc[not_nan] = df_to_process\n",
    "        \n",
    "        # implode and merge\n",
    "        df = df.groupby([\"sentence\", \"error\"]).agg(\n",
    "            {\n",
    "                \"masked\": list,\n",
    "                \"replace\": list,\n",
    "            }\n",
    "        ).reset_index()\n",
    "\n",
    "        # process masked sentences\n",
    "        df[\"masked\"] = df[\"masked\"].apply(join_masked)\n",
    "\n",
    "        final_dataset = pd.concat([final_dataset, df])\n",
    "\n",
    "    return Dataset.from_pandas(final_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1\n",
    "We will replace `[MASK]` with the suggestion that has biggest score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filling masks for shards: 100%|██████████| 10/10 [00:31<00:00,  3.15s/it]\n",
      "Creating json from Arrow format: 100%|██████████| 10/10 [00:00<00:00, 250.03ba/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4397950"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Experiment1(ProcessPrediction):\n",
    "    def process_prediction(self, data: list[PredictionData]) -> Iterator[str]:\n",
    "        for row in data:\n",
    "            yield row.predictions[0][\"token_str\"].strip()\n",
    "\n",
    "corrector = pipeline(\"fill-mask\", model=MODEL, tokenizer=MODEL, device=0, top_k=1)\n",
    "proc = Experiment1(corrector)\n",
    "\n",
    "result = create_dataset(proc)\n",
    "result.to_json(DATASET.parent / \"result-experiment-1.json\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filling masks for shards: 100%|██████████| 10/10 [00:51<00:00,  5.20s/it]\n",
      "Creating json from Arrow format: 100%|██████████| 10/10 [00:00<00:00, 260.05ba/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4397556"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import edit_distance\n",
    "\n",
    "class Experiment2(ProcessPrediction):\n",
    "    def process_prediction(self, data: list[PredictionData]) -> Iterator[str]:\n",
    "        for row in data:\n",
    "            error = row.error.split(\" \")\n",
    "            masked = row.masked\n",
    "            predictions = row.predictions\n",
    "            index = masked.index(\"[MASK]\")\n",
    "            \n",
    "            try:\n",
    "                invalid_word = error[index]\n",
    "\n",
    "                if invalid_word in [\".\", \",\", \"!\", \"?\"]:\n",
    "                    yield invalid_word\n",
    "\n",
    "                best = min([(edit_distance(prediction[\"token_str\"].strip(), invalid_word), prediction[\"token_str\"].strip()) for prediction in predictions], key=lambda x: x[0])            \n",
    "\n",
    "                yield best[1]\n",
    "            except IndexError:\n",
    "                yield row.predictions[0][\"token_str\"].strip()\n",
    "\n",
    "\n",
    "\n",
    "corrector = pipeline(\"fill-mask\", model=MODEL, tokenizer=MODEL, device=0, top_k=50)\n",
    "proc = Experiment2(corrector)\n",
    "result = create_dataset(proc)\n",
    "result.to_json(DATASET.parent / \"result-experiment-2.json\", orient=\"records\", lines=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
